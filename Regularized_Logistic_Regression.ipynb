{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Regularized Logistic Regression.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxZM3KyjSx5D"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkIN65qKUwCV"
      },
      "source": [
        "def create_matrices(data_frame, features, outputs):\r\n",
        "  # include intercept term (w0) => add a column of 1s in feature matrix\r\n",
        "  data_frame[\"intercept\"] = 1\r\n",
        "  features = [\"intercept\"] + features\r\n",
        "  features_matrix = np.array(data_frame[features])\r\n",
        "  output_matrix = np.array(data_frame[outputs])\r\n",
        "  return features_matrix, output_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58EtQwrrVqkz"
      },
      "source": [
        "**LOGISTIC FUNCTION**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2uW7konS124"
      },
      "source": [
        "def logistic_function(value):\r\n",
        "  return  1/ (1 + np.exp(-np.array(value)))"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GcHnMo4-V_vz"
      },
      "source": [
        "**PROBABILITY CALCULATION**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTK1wZ3LU2Jj"
      },
      "source": [
        "def predict_probability(feature_matrix, weights):\r\n",
        "  return logistic_function(np.dot(feature_matrix, weights))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTBu2VlHWHJZ"
      },
      "source": [
        "**REGULARIZED GRADIENT CALCULATION**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DoddqJq1S3kg"
      },
      "source": [
        "def L2Regularized_gradient(error, feature_matrix,  weights, l2_parameter, is_intercept):\r\n",
        "  if is_intercept:\r\n",
        "    return 2 * np.dot(np.transpose(feature_matrix), error) #intercept term is not regularized\r\n",
        "  else:\r\n",
        "   return 2 * np.dot(np.transpose(feature_matrix), error) - 2 * l2_parameter * weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oK1YdfL4WWNZ"
      },
      "source": [
        "**GRADIENT ASCENT**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGnIyjwYVBpS"
      },
      "source": [
        "def regularized_gradient_ascent(feature_matrix, output_matrix, weights, step_size, l2_parameter, max_iterations):\r\n",
        "  for i in range(max_iterations):\r\n",
        "    error = predict_output(feature_matrix, weights) - output_matrix\r\n",
        "    for j in range(len(weights)):\r\n",
        "      gradient = 0\r\n",
        "      if j == 0: #intercept term in weights\r\n",
        "        gradient = L2Regularized_gradient(error, feature_matrix[:, j], weights[j], l2_parameter, True)\r\n",
        "      else:\r\n",
        "        gradient =  L2Regularized_gradient(error, feature_matrix[:, j], weights[j], l2_parameter, False)\r\n",
        "      weights[j] = weights[j]  + step_size * gradient\r\n",
        "  return weights"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}