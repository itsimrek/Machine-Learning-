{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "logisticRegression.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRsc3GIeU1RV"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zY-qxKWlgCpz"
      },
      "source": [
        "**DATA PREPROCESSING**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFi7ZTPBgGX1"
      },
      "source": [
        "def create_matrices(data_frame, features, outputs):\r\n",
        "  # include intercept term (w0) => add a column of 1s in feature matrix\r\n",
        "  data_frame[\"intercept\"] = 1\r\n",
        "  features = [\"intercept\"] + features\r\n",
        "  features_matrix = np.array(data_frame[features])\r\n",
        "  output_matrix = np.array(data_frame[outputs])\r\n",
        "  return features_matrix, output_matrix"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQwa6GtDY1PF"
      },
      "source": [
        "**SIGMOID (LOGISTIC) FUNCTION**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgaMY9qHYzCD"
      },
      "source": [
        "def logistic_function(value):\r\n",
        "  return  1/ (1 + np.exp(-np.array(value)))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBqmUrRFbJ2n"
      },
      "source": [
        "**CALCULATE COST AND GRADIENT**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6SR2XKdewPN"
      },
      "source": [
        "def calculate_cost(feature_matrix, output_matrix,  weights):\r\n",
        "  h = predict_probability(feature_matrix, weights) # h = g(Xw)\r\n",
        "  return (np.sum(-output_matrix.dot(np.log(h)) - (1 - output_matrix).dot(np.log(1 - h)))) "
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSMXAjXobJol"
      },
      "source": [
        "def calculate_gradient(feature_matrix, error):\r\n",
        "    gradient = np.dot(np.transpose(feature_matrix), error)\r\n",
        "    return gradient"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCvdBQHRjSyM"
      },
      "source": [
        "**PREDICTION OF PROBABILITY**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJfedmy1jZeN"
      },
      "source": [
        "def predict_probability(feature_matrix, weights):\r\n",
        "  return logistic_function(np.dot(feature_matrix, weights))"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNqMeaVDi8Ec"
      },
      "source": [
        "**GRADIENT ASCENT FOR LOGISTIC REGRESSION**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohRPjiQpjEel"
      },
      "source": [
        "def logistic_regression(features_matrix, output_matrix, weights, step_size, max_iterations):\r\n",
        "  for i in range(max_iterations):\r\n",
        "    predictions = predict_probability(features_matrix, weights)\r\n",
        "    error = output_matrix - predictions\r\n",
        "    weights = weights  +  step_size * calculate_gradient(features_matrix, error)\r\n",
        "  return weights"
      ],
      "execution_count": 76,
      "outputs": []
    }
  ]
}