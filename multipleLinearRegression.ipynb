{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "multipleLinearRegression.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKqzwhSuYKA9"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56fbxc80YO1J"
      },
      "source": [
        "**CREATE MATRICES FROM THE DATA**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_vUNoowYOIH"
      },
      "source": [
        "def create_matrices(data_frame, features, outputs):\r\n",
        "  # include intercept term (w0) => add a column of 1s in feature matrix\r\n",
        "  data_frame[\"intercept\"] = 1\r\n",
        "  features = [\"intercept\"] + features\r\n",
        "  features_matrix = np.array(data_frame[features])\r\n",
        "  output_matrix = np.array(data_frame[outputs])\r\n",
        "  return features_matrix, output_matrix"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9vQrg1SfcWr"
      },
      "source": [
        "**PREDICTING VALUES**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q29w5XlWfpDu"
      },
      "source": [
        "def predict_output(feature_matrix, weights):\r\n",
        "  return np.dot(feature_matrix, weights)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_a2lzQk_dqVk"
      },
      "source": [
        "**COMPUTE COST AND GRADIENT**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFRWhmbKe2C8"
      },
      "source": [
        "def calculate_cost(feature_matrix, output_matrix, weights):\r\n",
        "  error = output_matrix -  predict_output(feature_matrix, weights)\r\n",
        "  return np.dot(np.transpose(error), error)"
      ],
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGq6qETmdypQ"
      },
      "source": [
        "def calculate_gradient(feature_matrix, output_matrix, weights):\r\n",
        "  error = predict_outputs(feature_matrix, weights) - output_matrix\r\n",
        "  return 2 * np.dot(np.transpose(feature_matrix), error) "
      ],
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gtxkz72Fld1k"
      },
      "source": [
        "**GRADIENT DESCENT ALGORITHM**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vW8_RR1mBuF"
      },
      "source": [
        "def gradient_descent(feature_matrix,output_matrix ,weights, step_size, tolerance):\r\n",
        "    converged=False\r\n",
        "    while not converged:\r\n",
        "       weights = weights -  step_size * calculate_gradient(feature_matrix, output_matrix, weights)\r\n",
        "       # calculate the magnitude of the gradient to assess convergence\r\n",
        "       if np.linalg.norm(calculate_gradient(feature_matrix, output_matrix, weights))  < tolerance:\r\n",
        "            converged=True\r\n",
        "    return weights"
      ],
      "execution_count": 191,
      "outputs": []
    }
  ]
}
